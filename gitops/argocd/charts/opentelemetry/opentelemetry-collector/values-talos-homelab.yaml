# SPDX-FileCopyrightText: Copyright (C) Nicolas Lamirault <nicolas.lamirault@gmail.com>
# SPDX-License-Identifier: Apache-2.0

---

opentelemetry-logs:
  extraEnvs:
  - name: OTEL_RESOURCE_ATTRIBUTES
    value: "k8s.pod.ip=$(MY_POD_IP)"
  - name: K8S_NAMESPACE
    valueFrom:
      fieldRef:
        apiVersion: v1
        fieldPath: metadata.namespace
  - name: K8S_NODE_NAME
    valueFrom:
      fieldRef:
        fieldPath: spec.nodeName
  - name: K8S_CLUSTER_NAME
    value: "portefaix-talos-homelab"

opentelemetry-metrics:
  extraEnvs:
  - name: OTEL_RESOURCE_ATTRIBUTES
    value: "k8s.pod.ip=$(MY_POD_IP)"
  - name: K8S_NAMESPACE
    valueFrom:
      fieldRef:
        apiVersion: v1
        fieldPath: metadata.namespace
  - name: K8S_NODE_NAME
    valueFrom:
      fieldRef:
        fieldPath: spec.nodeName
  - name: K8S_CLUSTER_NAME
    value: "portefaix-talos-homelab"

opentelemetry-metrics-cluster:
  extraEnvs:
  - name: OTEL_RESOURCE_ATTRIBUTES
    value: "k8s.pod.ip=$(MY_POD_IP)"
  - name: K8S_NAMESPACE
    valueFrom:
      fieldRef:
        apiVersion: v1
        fieldPath: metadata.namespace
  - name: K8S_NODE_NAME
    valueFrom:
      fieldRef:
        fieldPath: spec.nodeName
  - name: K8S_CLUSTER_NAME
    value: "portefaix-talos-homelab"

opentelemetry-traces:
  extraEnvs:
  - name: OTEL_RESOURCE_ATTRIBUTES
    value: "k8s.pod.ip=$(MY_POD_IP)"
  - name: K8S_NAMESPACE
    valueFrom:
      fieldRef:
        apiVersion: v1
        fieldPath: metadata.namespace
  - name: K8S_NODE_NAME
    valueFrom:
      fieldRef:
        fieldPath: spec.nodeName
  - name: K8S_CLUSTER_NAME
    value: "portefaix-talos-homelab"



# opentelemetry-collector:
#   resources:
#     limits:
#       # cpu: 500m
#       memory: 3Gi
#     requests:
#       cpu: 300m
#       memory: 500Mi

# envEnvFrom:
# - secretRef:
#     name: opentelemetry-datadog-credentials
# - secretRef:
#     name: opentelemetry-lightstep-credentials
# - secretRef:
#     name: opentelemetry-grafanacloud-credentials

# extraEnvs:
# - name: "K8S_NODE_NAME"
#   valueFrom:
#     fieldRef:
#       fieldPath: "spec.nodeName"
# - name: "K8S_POD_NAME"
#   valueFrom:
#     fieldRef:
#       fieldPath: "metadata.name"
# - name: "K8S_NAMESPACE"
#   valueFrom:
#     fieldRef:
#       fieldPath: "metadata.namespace"

# serviceMonitor:
#   enabled: true
#   # extraLabels:
#   #   prometheus.io/operator: portefaix

# # targetAllocator:
# #   replicas: 1

# collectors:
# - name: metrics
#   enabled: true
#   mode: statefulset
#   image:
#     repository: ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib
#     tag: 0.80.0
#   serviceMonitor:
#     enabled: true
#     additionalLabels:
#       #   prometheus.io/operator: portefaix
#       observability: portefaix

#   targetAllocator:
#     enabled: true
#     # serviceAccount: opentelemetry-targetallocator-sa
#     allocationStrategy: consistent-hashing
#     filterStrategy: relabel-config
#     image:
#       repository: ghcr.io/open-telemetry/opentelemetry-operator/target-allocator
#       tag: 0.80.0
#     replicas: 1
#     prometheusCR:
#       enabled: true
#       serviceMonitorSelector:
#         prometheus.io/operator: portefaix
#         # observability: portefaix
#     serviceMonitor:
#       enabled: true
#       additionalLabels:
#         # prometheus.io/operator: portefaix
#         observability: portefaix



#   config:
#     extensions:
#       health_check:

#       memory_ballast:
#         size_in_percentage: 20

#       # k8s_observer:
#       #   auth_type: serviceAccount
#       #   node: ${K8S_NODE_NAME}
#       #   observe_pods: true
#       #   observe_nodes: true

#       pprof:
#         endpoint: :1888

#       zpages:
#         endpoint: :55679

#       basicauth/grafanacloud:
#         client_auth:
#           username: "${GRAFANA_CLOUD_METRICS_ID}"
#           password: "${GRAFANA_CLOUD_METRICS_APIKEY}"

#     receivers:
#       hostmetrics:
#         collection_interval: 60s
#         scrapers:
#           cpu:
#           load:
#           memory:
#           disk:
#           filesystem:
#           network:
#           processes:

#       prometheus:
#         config:
#           global:
#             scrape_interval: 60s
#             scrape_timeout: 60s
#             evaluation_interval: 60s
#             # external_labels:
#             #   project: portefaix-homelab
#           scrape_configs:
#           - job_name: "otel-collector"
#             scrape_interval: 30s
#             static_configs:
#             - targets: ["0.0.0.0:8888"]
#         target_allocator:
#           endpoint: http://metrics-targetallocator:80
#           interval: 30s
#           collector_id: ${POD_NAME}
#           http_sd_config:
#             refresh_interval: 60s

#       # k8s_cluster:
#       #   collection_interval: 60s
#       #   distribution: kubernetes
#       #   node_conditions_to_report: [Ready, DiskPressure, MemoryPressure, PIDPressure, NetworkUnavailable]
#       #   allocatable_types_to_report: [cpu, memory, ephemeral-storage, storage]

#       # k8s_events:
#       #   auth_type: "serviceAccount"

#       # kubeletstats:
#       #   collection_interval: 60s
#       #   auth_type: "serviceAccount"
#       #   endpoint: "${K8S_NODE_NAME}:10250"
#       #   insecure_skip_verify: true

#     processors:
#       batch:
#         send_batch_size: 1500
#         send_batch_max_size: 1500
#         timeout: 15s

#       # Data sources: traces, metrics, logs
#       memory_limiter:
#         limit_percentage: 90
#         spike_limit_percentage: 30
#         check_interval: 5s

#       # metricstransform:
#       #   transforms:
#       #      include: .+
#       #      match_type: regexp
#       #      action: update
#       #      operations:
#       #        - action: add_label
#       #          new_label: kubernetes.cluster.id
#       #          new_value: kind-local
#       #        - action: add_label
#       #          new_label: kubernetes.name
#       #          new_value: local

#       k8sattributes:
#         passthrough: false
#         pod_association:
#         - sources:
#           - from: resource_attribute
#             name: k8s.pod.name
#         extract:
#           metadata:
#           - k8s.namespace.name
#           - k8s.pod.name
#           - k8s.pod.uid
#           - k8s.node.name
#           - k8s.pod.start_time
#           # FIXME: https://github.com/open-telemetry/opentelemetry-collector-contrib/issues/23067
#           # - k8s.deployment.name
#           # - k8s.replicaset.name
#           # - k8s.replicaset.uid
#           # - k8s.daemonset.name
#           # - k8s.daemonset.uid
#           # - k8s.statefulset.name
#           # - k8s.statefulset.uid
#           - k8s.job.name
#           - k8s.job.uid
#           - k8s.cronjob.name
#           - container.image.tag
#           - container.image.name
#           # # For Routing:
#           # labels:
#           # - tag_name: tenantId
#           #   key: "tenant-id"
#           #   from: namespace

#       resource:
#         attributes:
#         - key: collector.name
#           value: "${KUBE_POD_NAME}"
#           action: insert

#       # https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/processor/routingprocessor/README.md
#       # routing:
#       #   from_attribute: tenantId
#       #   attribute_source: resource
#       #   table:
#       #   - value: k3s-homelab
#       #     exporters: [logging, otlp/xxxxx]
#       #   - value: k3s-cloudprovider
#       #     exporters: [logging, otlp/yyyyy]

#       # The resource detection processor adds context related to the cloud provider the Collector is running on.
#       # It is necessary **only** on gateway deployment mode, to correctly identify the host that telemetry data comes from.
#       # resourcedetection:
#       #   detectors: [gcp, ecs, ec2, azure, system]

#     exporters:
#       logging:
#         verbosity: detailed
#         # verbosity: normal

#       # prometheus:
#       #   endpoint: "0.0.0.0:9090"
#       #   metric_expiration: 180m
#       #   # enable_open_metrics: true
#       #   resource_to_telemetry_conversion:
#       #     enabled: true

#       # prometheusremotewrite/mimir:
#       #   endpoint: http://mimir-gateway.monitoring.svc.cluster.local:80/api/v1/push

#       # prometheusremotewrite/grafanacloud:
#       #   endpoint: https://prometheus-us-central1.grafana.net/api/prom/push
#       #   auth:
#       #     authenticator: basicauth/grafanacloud

#       # otlp/honeycomb_metrics:
#       #   endpoint: "api.honeycomb.io:443"
#       #   headers:
#       #     "x-honeycomb-team": "${HONEYCOMB_API_KEY}"
#       #     "x-honeycomb-dataset": "portefaix-homelab-metrics"

#       # otlp/lightstep:
#       #   endpoint: ingest.lightstep.com:443
#       #   headers:
#       #     "lightstep-access-token": "${LIGHTSTEP_TOKEN}"

#       # datadog:
#       #   # env: prod
#       #   # service: opentelemetry
#       #   # tags:
#       #   #   - cloud:homelab
#       #   api:
#       #     key: ${DATADOG_API_KEY}
#       #     site: datadoghq.com

#     service:
#       telemetry:
#         logs:
#           level: info
#           encoding: json
#         metrics:
#           level: detailed
#           address: 0.0.0.0:8888

#       extensions:
#       - health_check
#       - memory_ballast
#       # - k8s_observer
#       - pprof
#       - zpages
#       # - basicauth/grafanacloud

#       pipelines:
#         metrics:
#           receivers:
#           - hostmetrics
#           - prometheus
#           # - k8s_cluster
#           # - kubeletstats
#           # - receiver_creator
#           processors:
#           - batch
#           - memory_limiter
#           # - metricstransform
#           - k8sattributes
#           # - resourcedetection/gce
#           exporters:
#           - logging
#           # - prometheus
#           # - prometheusremotewrite/mimir
#           # - prometheusremotewrite/grafanacloud
#           # - otlp/honeycomb_metrics
#           # - otlp/lightstep
#           # - datadog

# - name: traces
#   enabled: true
#   mode: statefulset
#   image:
#     repository: ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib
#     tag: 0.80.0
#   serviceMonitor:
#     enabled: true
#     additionalLabels:
#       # prometheus.io/operator: portefaix
#       observability: portefaix

#   targetAllocator:
#     enabled: false

#   resources:
#     limits:
#       # cpu: 500m
#       memory: 1Gi
#     requests:
#       cpu: 200m
#       memory: 500Mi

#   config:
#     extensions:
#       health_check:

#       memory_ballast:
#         size_in_percentage: 20

#       # k8s_observer:
#       #   auth_type: serviceAccount
#       #   node: ${K8S_NODE_NAME}
#       #   observe_pods: true
#       #   observe_nodes: true

#       pprof:
#         endpoint: :1888

#       zpages:
#         endpoint: :55679

#       basicauth/grafanacloud:
#         client_auth:
#           username: "${GRAFANA_CLOUD_TRACES_ID}"
#           password: "${GRAFANA_CLOUD_TRACES_APIKEY}"

#     receivers:
#       jaeger:
#         protocols:
#           grpc:
#             endpoint: 0.0.0.0:14250
#           thrift_http:
#             endpoint: 0.0.0.0:14268
#           thrift_compact:
#             endpoint: 0.0.0.0:6831

#       otlp:
#         protocols:
#           grpc:
#             endpoint: 0.0.0.0:4317
#           http:
#             endpoint: 0.0.0.0:4318

#       # zipkin:
#       #   endpoint: 0.0.0.0:9411

#     processors:
#       batch:
#         send_batch_max_size: 1000
#         timeout: 15s
#         send_batch_size: 800

#       # Data sources: traces, metrics, logs
#       memory_limiter:
#         limit_percentage: 90
#         spike_limit_percentage: 30
#         check_interval: 5s

#       resource:
#         attributes:
#         - key: collector.name
#           value: "${KUBE_POD_NAME}"
#           action: insert

#       # The resource detection processor adds context related to the cloud provider the Collector is running on.
#       # It is necessary **only** on gateway deployment mode, to correctly identify the host that telemetry data comes from.
#       # resourcedetection:
#       #   detectors: [gcp, ecs, ec2, azure, system]

#     exporters:
#       logging:
#         # verbosity: detailed
#         verbosity: normal

#       # Data sources: traces, metrics, logs
#       otlp/tempo:
#         endpoint: tempo-distributor.tracing.svc.cluster.local:4317
#         tls:
#           insecure_skip_verify: true
#           insecure: true

#       # otlp/honeycomb_metrics:
#       #   endpoint: "api.honeycomb.io:443"
#       #   headers:
#       #     "x-honeycomb-team": "${HONEYCOMB_API_KEY}"
#       #     "x-honeycomb-dataset": "portefaix-homelab-metrics"

#       # otlp/lightstep:
#       #   endpoint: ingest.lightstep.com:443
#       #   headers:
#       #     "lightstep-access-token": "${LIGHTSTEP_TOKEN}"

#       # otlp/grafanacloud:
#       #   endpoint: tempo-us-central1.grafana.net:443
#       #   auth:
#       #     authenticator: basicauth/grafanacloud

#       # datadog:
#       #   # env: prod
#       #   # service: opentelemetry
#       #   # tags:
#       #   #   - cloud:homelab
#       #   api:
#       #     key: ${DATADOG_API_KEY}
#       #     site: datadoghq.com

#     service:
#       telemetry:
#         logs:
#           level: info
#           encoding: json
#         metrics:
#           level: detailed
#           address: 0.0.0.0:8888

#       extensions:
#       - health_check
#       - memory_ballast
#       # - k8s_observer
#       - pprof
#       - zpages
#       - basicauth/grafanacloud

#       pipelines:
#         traces:
#           receivers:
#           - otlp
#           processors:
#           - batch
#           # - k8sattributes
#           - memory_limiter
#           - resource
#           exporters:
#           - logging
#           - otlp/tempo
#           # - otlp/grafanacloud
#           # - otlp/honeycomb_traces
#           # - otlp/lightstep
#           # - datadog

# - name: logs
#   enabled: true
#   mode: statefulset
#   image:
#     repository: ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib
#     tag: 0.80.0
#   serviceMonitor:
#     enabled: true
#     additionalLabels:
#       # prometheus.io/operator: portefaix
#       observability: portefaix

#   targetAllocator:
#     enabled: false

#   resources:
#     limits:
#       # cpu: 500m
#       memory: 1Gi
#     requests:
#       cpu: 400m
#       memory: 500Mi

#   config:
#     extensions:
#       health_check:

#       memory_ballast:
#         size_in_percentage: 20

#       # k8s_observer:
#       #   auth_type: serviceAccount
#       #   node: ${K8S_NODE_NAME}
#       #   observe_pods: true
#       #   observe_nodes: true

#       pprof:
#         endpoint: :1888

#       zpages:
#         endpoint: :55679

#       basicauth/grafanacloud:
#         client_auth:
#           username: "${GRAFANA_CLOUD_LOGS_ID}"
#           password: "${GRAFANA_CLOUD_LOGS_APIKEY}"

#     receivers:
#       otlp:
#         protocols:
#           grpc:
#           http:

#       fluentforward:
#         endpoint: 0.0.0.0:24224

#       k8s_events:

#     processors:
#       transform:
#         log_statements:
#         - context: log
#           statements:
#           - merge_maps(attributes, attributes["kubernetes"], "upsert")
#           - delete_key(attributes, "kubernetes")
#       attributes:
#         actions:
#         - action: insert
#           key: namespace
#           from_attribute: namespace_name
#         - action: insert
#           key: pod
#           from_attribute: pod_name
#         - action: insert
#           key: container
#           from_attribute: container_name
#         - action: insert
#           key: host
#           from_attribute: host
#         - action: insert
#           key: loki.attribute.labels
#           value: [namespace, pod, host, container]

#       batch:
#         send_batch_max_size: 1000
#         timeout: 15s
#         send_batch_size: 800

#       # Data sources: traces, metrics, logs
#       memory_limiter:
#         limit_percentage: 90
#         spike_limit_percentage: 30
#         check_interval: 5s

#       # The resource detection processor adds context related to the cloud provider the Collector is running on.
#       # It is necessary **only** on gateway deployment mode, to correctly identify the host that telemetry data comes from.
#       # resourcedetection:
#       #   detectors: [gcp, ecs, ec2, azure, system]

#     exporters:
#       logging:
#         # verbosity: detailed
#         verbosity: normal

#       # https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/exporter/lokiexporter/README.md
#       loki:
#         endpoint: http://loki-gateway.logging.svc.cluster.local:80/loki/api/v1/push
#         headers:
#           X-Scope-OrgID: portefaix-talos-homelab
#         tls:
#           insecure: true

#       # loki/grafanacloud:
#       #   endpoint: https://logs-prod-us-central1.grafana.net/loki/api/v1/push
#       #   headers:
#       #     X-Scope-OrgID: portefaix-talos-homelab
#       #   auth:
#       #     authenticator: basicauth/grafanacloud

#       # otlp/lightstep:
#       #   endpoint: ingest.lightstep.com:443
#       #   headers:
#       #     "lightstep-access-token": "${LIGHTSTEP_TOKEN}"

#       # datadog:
#       #   # env: prod
#       #   # service: opentelemetry
#       #   # tags:
#       #   #   - cloud:homelab
#       #   api:
#       #     key: ${DATADOG_API_KEY}
#       #     site: datadoghq.com

#     service:
#       telemetry:
#         logs:
#           level: info
#           encoding: json
#         metrics:
#           level: detailed
#           address: 0.0.0.0:8888

#       extensions:
#       - health_check
#       - memory_ballast
#       - pprof
#       - zpages
#       - basicauth/grafanacloud

#       pipelines:
#         logs:
#           receivers:
#           - fluentforward
#           # - otlp
#           - k8s_events
#           processors:
#           - batch
#           - memory_limiter
#           - transform
#           - attributes
#           exporters:
#           - logging
#           - loki
#           # - loki/grafanacloud
